{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b412afa8-64af-4226-97cc-b157613393f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sys\n",
    "# import gymnasium as gym\n",
    "# sys.modules[\"gym\"] = gym\n",
    "import gym\n",
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16240bb9-6283-4faa-baee-5fc4b347ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5796eea-1d13-494b-85be-835f64d4e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1578350d-b5a0-48a4-b702-828966e0427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf11781b-50d5-4f3f-b7a2-bc66dea71f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5cd2440-933a-4bf6-8d5a-374d4e8de525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">999,809/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:10:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">1,817 it/s</span> ]\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">999,809/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:10:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">1,817 it/s</span> ]</pre>\n"
      ],
      "text/plain": [
       "\r",
       "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m999,809/1,000,000 \u001b[0m [ \u001b[33m0:10:16\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m1,817 it/s\u001b[0m ]\n",
       "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m999,809/1,000,000 \u001b[0m [ \u001b[33m0:10:16\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m1,817 it/s\u001b[0m ]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert = PPO(\n",
    "    policy=MlpPolicy,\n",
    "    env=env,\n",
    "    seed=0,\n",
    "    batch_size=64,\n",
    "    ent_coef=0.0,\n",
    "    learning_rate=0.0003,\n",
    "    n_epochs=10,\n",
    "    n_steps=64,\n",
    ")\n",
    "expert.learn(1_000_000, progress_bar=True)\n",
    "expert.save(\"ppo_CartPole_expert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae356446-4d15-459c-9004-87e0abebf312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Linux-5.15.0-58-generic-x86_64-with-glibc2.35 # 64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023\n",
      "- Python: 3.10.6\n",
      "- Stable-Baselines3: 1.7.0\n",
      "- PyTorch: 1.13.1+cu117\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.24.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Linux-5.15.0-58-generic-x86_64-with-glibc2.35 # 64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023\n",
      "- Python: 3.10.6\n",
      "- Stable-Baselines3: 1.7.0\n",
      "- PyTorch: 1.13.1+cu117\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.24.1\n",
      "- Gym: 0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expert = PPO.load(\"ppo_CartPole_expert.zip\", print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c74804-53d8-43e0-89cb-7b0c0fe62994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad1slav/Diploma/rl-venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "reward, _ = evaluate_policy(expert, env, 10)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c8a2a1-ee13-4bcd-969f-385d3bd7408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rollouts = rollout.rollout(\n",
    "    expert,\n",
    "    DummyVecEnv([lambda: RolloutInfoWrapper(env)]),\n",
    "    rollout.make_sample_until(min_timesteps=None, min_episodes=50),\n",
    "    rng=rng,\n",
    ")\n",
    "transitions = rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660f7383-a1cf-4dc5-9019-c98dae0b81c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `rollout` function generated a list of 50 <class 'imitation.data.types.TrajectoryWithRew'>.\n",
      "After flattening, this list is turned into a <class 'imitation.data.types.Transitions'> object containing 25000 transitions.\n",
      "The transitions object contains arrays for: obs, acts, infos, next_obs, dones.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\"\"The `rollout` function generated a list of {len(rollouts)} {type(rollouts[0])}.\n",
    "After flattening, this list is turned into a {type(transitions)} object containing {len(transitions)} transitions.\n",
    "The transitions object contains arrays for: {', '.join(transitions.__dict__.keys())}.\"\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "653eaa79-f614-458a-882e-aba9292e2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    demonstrations=transitions,\n",
    "    rng=rng,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c0b603-9ce3-43b5-9b17-8a2d54c6b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward before training: 9.5\n"
     ]
    }
   ],
   "source": [
    "reward_before_training, _ = evaluate_policy(bc_trainer.policy, env, 10)\n",
    "print(f\"Reward before training: {reward_before_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef168050-1228-48b8-8ac7-85e3b84f7154",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 0         |\n",
      "|    ent_loss       | -0.000158 |\n",
      "|    entropy        | 0.158     |\n",
      "|    epoch          | 0         |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 183       |\n",
      "|    loss           | 0.118     |\n",
      "|    neglogp        | 0.118     |\n",
      "|    prob_true_act  | 0.917     |\n",
      "|    samples_so_far | 32        |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "452batch [00:00, 762.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 500       |\n",
      "|    ent_loss       | -0.000152 |\n",
      "|    entropy        | 0.152     |\n",
      "|    epoch          | 0         |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 184       |\n",
      "|    loss           | 0.125     |\n",
      "|    neglogp        | 0.125     |\n",
      "|    prob_true_act  | 0.922     |\n",
      "|    samples_so_far | 16032     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "769batch [00:01, 777.50batch/s]\n",
      "926batch [00:01, 762.24batch/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 1000      |\n",
      "|    ent_loss       | -0.000244 |\n",
      "|    entropy        | 0.244     |\n",
      "|    epoch          | 1         |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 185       |\n",
      "|    loss           | 0.229     |\n",
      "|    neglogp        | 0.229     |\n",
      "|    prob_true_act  | 0.84      |\n",
      "|    samples_so_far | 32032     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1481batch [00:01, 781.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 1500      |\n",
      "|    ent_loss       | -0.000173 |\n",
      "|    entropy        | 0.173     |\n",
      "|    epoch          | 1         |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 187       |\n",
      "|    loss           | 0.144     |\n",
      "|    neglogp        | 0.144     |\n",
      "|    prob_true_act  | 0.898     |\n",
      "|    samples_so_far | 48032     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1560batch [00:02, 783.75batch/s]\n",
      "1562batch [00:02, 765.12batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward after training: 500.0\n"
     ]
    }
   ],
   "source": [
    "bc_trainer.train(n_epochs=2, progress_bar=True)\n",
    "reward_after_training, _ = evaluate_policy(bc_trainer.policy, env, 10)\n",
    "print(f\"Reward after training: {reward_after_training}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-venv",
   "language": "python",
   "name": "rl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
