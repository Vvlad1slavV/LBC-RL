{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc3954-1c37-4448-b4a5-6a21ced91486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import gymnasium as gym\n",
    "# sys.modules[\"gym\"] = gym\n",
    "import gym\n",
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa9c31-b71e-4dc0-8050-d44d2fb05f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecVideoRecorder\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2140a-e237-454a-a6ac-f25039e30a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2af40-9352-4e0e-9b65-1182675499eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441e510-2dd4-4a68-b288-50ed2ed5f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"MountainCarContinuous-v0\"\n",
    "NUM_CPU = 32  # Number of processes to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541782fa-f9ad-470b-9214-c24b07050f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MountainCar_utils.observation_wrapper import MountainCarContinuousObsWrapper\n",
    "\n",
    "def wrapper(env):\n",
    "    env = MountainCarContinuousObsWrapper(env) \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70678eda-16c0-4784-9eb4-4a8dc0f53a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expert = PPO.load(\"./policy/ppo_MountainCarContinuous_expert38984_n32b64.zip\", print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b18aa-74e2-4ca0-b28f-49a2bc13b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "import dataclasses\n",
    "\n",
    "def make_env(env_id):\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env = RolloutInfoWrapper(env) # Wrapper to save origin obs\n",
    "        env = wrapper(env) # Wrapper Obs\n",
    "        return env\n",
    "    \n",
    "    return _init\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562bc164-7e93-4c36-84d8-98d9f53a1b03",
   "metadata": {},
   "source": [
    "# BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5bcb6-877e-4d25-8d58-0ec85bb758cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_env = DummyVecEnv([make_env(env_id)]*NUM_CPU)\n",
    "bc_env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f3fc2-0fa6-4902-aae2-1aa392864d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPISODES = 500\n",
    "\n",
    "rollouts = rollout.rollout(\n",
    "    expert,\n",
    "    bc_env,\n",
    "    rollout.make_sample_until(min_timesteps=None, min_episodes=NUM_EPISODES),\n",
    "    rng = rng,\n",
    "    unwrap = True,\n",
    ")\n",
    "\n",
    "bc_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0aeae-2fe6-4433-a82c-cd5789340d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rollouts = [rollout for rollout in rollouts if sum(rollout.rews) > 94]\n",
    "transitions = rollout.flatten_trajectories(top_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc740c1-d128-404b-88e1-328d58a27d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(rollout.rollout_stats(rollouts))\n",
    "pprint(rollout.rollout_stats(top_rollouts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672d727-7370-4b87-9d76-6c0f0f9a55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"The `rollout` function generated a list of {len(top_rollouts)} {type(top_rollouts[0])}.\n",
    "After flattening, this list is turned into a {type(transitions)} object containing {len(transitions)} transitions.\n",
    "The transitions object contains arrays for: {', '.join(transitions.__dict__.keys())}.\"\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c164543-d04e-4a0c-bb7f-aba625ba628c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "\n",
    "env = gym.make(env_id)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    demonstrations=transitions,\n",
    "    rng=rng,\n",
    "    policy=ActorCriticPolicy(observation_space=env.observation_space,\n",
    "                             action_space=env.action_space,\n",
    "                             lr_schedule=lambda _: th.finfo(th.float32).max,\n",
    "                             net_arch=[64, 64]\n",
    "                             )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45bc20-573c-44b7-b4d7-caefe1e9e5f7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bc_trainer.train(n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfe291-931b-4f81-953c-dfc398d5715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_trainer.save_policy('policy/bc.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ff961-4ca5-414a-8d72-6aca43c8df91",
   "metadata": {},
   "source": [
    "# DAgger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d04a75-61c0-42f2-aac3-68c365aa3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from imitation.algorithms import bc\n",
    "from imitation.algorithms.dagger import SimpleDAggerTrainer\n",
    "\n",
    "dagger_env = DummyVecEnv([make_env(env_id)]*NUM_CPU)\n",
    "dagger_env.observation_space\n",
    "\n",
    "env = gym.make(env_id)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb866c-eab4-4996-beeb-2a904982f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    rng=rng,\n",
    "    policy=ActorCriticPolicy(observation_space=env.observation_space,\n",
    "                             action_space=env.action_space,\n",
    "                             lr_schedule=lambda _: th.finfo(th.float32).max,\n",
    "                             net_arch=[64, 64]\n",
    "                             )\n",
    ")\n",
    "\n",
    "with tempfile.TemporaryDirectory(prefix=\"dagger_\") as tmpdir:\n",
    "    print(tmpdir)\n",
    "    dagger_trainer = SimpleDAggerTrainer(\n",
    "        venv = dagger_env,\n",
    "        scratch_dir = tmpdir,\n",
    "        expert_policy = expert,\n",
    "        bc_trainer = bc_trainer,\n",
    "        rng = np.random.default_rng(),\n",
    "    )\n",
    "\n",
    "    # dagger_trainer.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98bc9c-2951-4e75-9282-aa14393b8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dagger_trainer.policy.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d1de8-e3eb-444e-bfb6-14e11533f770",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e28162-6697-4670-87c6-fa829ee81230",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(env_id)\n",
    "env = gnwrapper.Animation(env)\n",
    "# env = gym.wrappers.RecordVideo(env, 'video')\n",
    "# env = make_vec_env(env_id, wrapper_class=wrapper_image, n_envs=1)\n",
    "# env = VecVideoRecorder(env, './video', True, 1000)\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = bc_trainer.policy.predict(np.asarray(obs))\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    if dones:\n",
    "        break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006da05a-72ca-4a81-863f-4b5fcda9fb07",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(env_id)\n",
    "env = wrapper(env)\n",
    "env = gnwrapper.Animation(env)\n",
    "# env = wrapper(env)\n",
    "# env = gym.wrappers.RecordVideo(env, 'video')\n",
    "# env = make_vec_env(env_id, wrapper_class=wrapper, n_envs=1)\n",
    "# env = VecVideoRecorder(env, './video', lambda x: True, 1000)\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = expert.predict(obs.copy())\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    if dones:\n",
    "        break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf24973-e7d2-4ef6-b32d-c9ba7942a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbaae8b-f547-4b8d-b36a-9fd424eeafb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_env_angle = make_vec_env(env_id, wrapper_class=wrapper, n_envs=10)\n",
    "test_env = make_vec_env(env_id, n_envs=10)\n",
    "\n",
    "expert_reward, expert_reward_std = evaluate_policy(expert, test_env_angle, 100)\n",
    "bc_reward, bc_reward_std = evaluate_policy(bc_trainer.policy, test_env, 100)\n",
    "# noob_reward, noob_reward_std = evaluate_policy(noob, test_env, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262688b7-6a64-44ed-86bf-c74fea728463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'expert reward {expert_reward:.2f} +/- {expert_reward_std:.2f}')\n",
    "print(f'BC reward {bc_reward:.2f} +/- {bc_reward_std:.2f}')\n",
    "# print(f'noob reward {noob_reward} +/- {noob_reward_std}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-venv",
   "language": "python",
   "name": "rl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
